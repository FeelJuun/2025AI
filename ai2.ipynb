{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9517d262-56ce-442a-b2ba-acd979e47977",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "⚠️ CuPy 없음 - CPU만 사용\n",
      "⚠️ RAPIDS 없음\n",
      "🧠 PyTorch 사용 가능 - 딥러닝 활성화!\n",
      "👹 H200 GPU 풀파워 괴물 사냥!\n",
      "============================================================\n",
      "🔥 NVIDIA H200 + 140GB 메모리 풀가동!\n",
      "🎯 목표: 0.5120+ (괴물 완전 제압!)\n",
      "⚡ GPU 가속 딥러닝 + 메가 앙상블 + 극한 최적화\n",
      "============================================================\n",
      "💪 H200 풀파워 모드 활성화!\n",
      "🎯 목표: 0.5120+ (괴물 완전 제압!)\n",
      "\n",
      "==================== PyTorch 딥러닝 ====================\n",
      "\n",
      "🧠 전략 1: PyTorch 딥러닝 (H200 GPU 가속)!\n",
      "  🔬 H200 극한 전처리 시작... (시드: 42)\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "# GPU 가속 라이브러리들\n",
    "try:\n",
    "    import cupy as cp\n",
    "    GPU_AVAILABLE = True\n",
    "    print(\"🔥 CuPy 사용 가능 - GPU 가속 활성화!\")\n",
    "except:\n",
    "    import numpy as cp\n",
    "    GPU_AVAILABLE = False\n",
    "    print(\"⚠️ CuPy 없음 - CPU만 사용\")\n",
    "\n",
    "try:\n",
    "    import cudf\n",
    "    import cuml\n",
    "    from cuml.ensemble import RandomForestClassifier as cuRF\n",
    "    from cuml.linear_model import LogisticRegression as cuLR\n",
    "    RAPIDS_AVAILABLE = True\n",
    "    print(\"🚀 RAPIDS 사용 가능 - GPU ML 가속!\")\n",
    "except:\n",
    "    RAPIDS_AVAILABLE = False\n",
    "    print(\"⚠️ RAPIDS 없음\")\n",
    "\n",
    "# 기본 라이브러리들\n",
    "from sklearn.model_selection import StratifiedKFold, cross_val_score\n",
    "from sklearn.preprocessing import LabelEncoder, StandardScaler, PolynomialFeatures\n",
    "from sklearn.feature_selection import SelectKBest, f_classif, RFECV\n",
    "from sklearn.ensemble import RandomForestClassifier, ExtraTreesClassifier, VotingClassifier\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "from sklearn.metrics import f1_score\n",
    "from sklearn.calibration import CalibratedClassifierCV\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "import xgboost as xgb\n",
    "import lightgbm as lgb\n",
    "import catboost as cb\n",
    "\n",
    "# 고급 최적화\n",
    "try:\n",
    "    import optuna\n",
    "    from optuna.integration import XGBoostPruningCallback\n",
    "    OPTUNA_AVAILABLE = True\n",
    "    print(\"🎯 Optuna 사용 가능 - 베이지안 최적화!\")\n",
    "except:\n",
    "    OPTUNA_AVAILABLE = False\n",
    "\n",
    "# 딥러닝\n",
    "try:\n",
    "    import torch\n",
    "    import torch.nn as nn\n",
    "    import torch.optim as optim\n",
    "    from torch.utils.data import Dataset, DataLoader\n",
    "    PYTORCH_AVAILABLE = True\n",
    "    print(\"🧠 PyTorch 사용 가능 - 딥러닝 활성화!\")\n",
    "except:\n",
    "    PYTORCH_AVAILABLE = False\n",
    "\n",
    "import time\n",
    "from multiprocessing import Pool, cpu_count\n",
    "\n",
    "class H200MonsterKiller:\n",
    "    \"\"\"H200 GPU 풀파워 괴물 제압기 - 0.5120+ 목표\"\"\"\n",
    "    \n",
    "    def __init__(self):\n",
    "        self.submissions = {}\n",
    "        self.best_score = 0.5109\n",
    "        \n",
    "        # GPU 메모리 정보\n",
    "        if GPU_AVAILABLE:\n",
    "            print(f\"🔥 GPU 메모리: {cp.cuda.Device().mem_info[1] / 1024**3:.1f} GB\")\n",
    "            \n",
    "        print(\"💪 H200 풀파워 모드 활성화!\")\n",
    "        print(\"🎯 목표: 0.5120+ (괴물 완전 제압!)\")\n",
    "        \n",
    "    def load_and_ultimate_preprocess(self, random_seed=42):\n",
    "        \"\"\"H200 파워로 극한 전처리\"\"\"\n",
    "        np.random.seed(random_seed)\n",
    "        \n",
    "        train_df = pd.read_csv('train.csv')\n",
    "        test_df = pd.read_csv('test.csv')\n",
    "        \n",
    "        print(f\"  🔬 H200 극한 전처리 시작... (시드: {random_seed})\")\n",
    "        \n",
    "        feature_cols = [col for col in train_df.columns if col not in ['ID', 'Cancer']]\n",
    "        \n",
    "        X_train = train_df[feature_cols].copy()\n",
    "        y_train = train_df['Cancer'].copy()\n",
    "        X_test = test_df[feature_cols].copy()\n",
    "        \n",
    "        # 1. 기본 전처리\n",
    "        categorical_cols = X_train.select_dtypes(include=['object']).columns\n",
    "        \n",
    "        for col in categorical_cols:\n",
    "            le = LabelEncoder()\n",
    "            X_train[col] = le.fit_transform(X_train[col].astype(str))\n",
    "            \n",
    "            test_values = X_test[col].astype(str)\n",
    "            test_encoded = []\n",
    "            for val in test_values:\n",
    "                if val in le.classes_:\n",
    "                    test_encoded.append(le.transform([val])[0])\n",
    "                else:\n",
    "                    test_encoded.append(0)\n",
    "            X_test[col] = test_encoded\n",
    "        \n",
    "        # 결측값 처리\n",
    "        numeric_cols = X_train.select_dtypes(include=[np.number]).columns\n",
    "        for col in numeric_cols:\n",
    "            median_val = X_train[col].median()\n",
    "            X_train[col].fillna(median_val, inplace=True)\n",
    "            X_test[col].fillna(median_val, inplace=True)\n",
    "        \n",
    "        # 2. 의료 도메인 지식 피처 (고급 버전)\n",
    "        print(\"  🏥 고급 의료 도메인 피처 생성...\")\n",
    "        \n",
    "        # 갑상선암 위험 점수 (의료 논문 기반 가중치)\n",
    "        X_train['Thyroid_Risk_Score'] = (\n",
    "            X_train['Family_Background'] * 0.35 +\n",
    "            X_train['Radiation_History'] * 0.30 +\n",
    "            X_train['Iodine_Deficiency'] * 0.20 +\n",
    "            (X_train['Gender'] == 1) * 0.15\n",
    "        )\n",
    "        X_test['Thyroid_Risk_Score'] = (\n",
    "            X_test['Family_Background'] * 0.35 +\n",
    "            X_test['Radiation_History'] * 0.30 +\n",
    "            X_test['Iodine_Deficiency'] * 0.20 +\n",
    "            (X_test['Gender'] == 1) * 0.15\n",
    "        )\n",
    "        \n",
    "        # 호르몬 프로파일 분석\n",
    "        # TSH 정상 범위: 0.4-4.0 mIU/L\n",
    "        X_train['TSH_Category'] = 0  # 정상\n",
    "        X_train.loc[X_train['TSH_Result'] < 0.4, 'TSH_Category'] = -1  # 낮음 (갑상선기능항진)\n",
    "        X_train.loc[X_train['TSH_Result'] > 4.0, 'TSH_Category'] = 1   # 높음 (갑상선기능저하)\n",
    "        \n",
    "        X_test['TSH_Category'] = 0\n",
    "        X_test.loc[X_test['TSH_Result'] < 0.4, 'TSH_Category'] = -1\n",
    "        X_test.loc[X_test['TSH_Result'] > 4.0, 'TSH_Category'] = 1\n",
    "        \n",
    "        # T4 정상 범위: 5.0-12.0 μg/dL\n",
    "        X_train['T4_Category'] = 0\n",
    "        X_train.loc[X_train['T4_Result'] < 5.0, 'T4_Category'] = -1\n",
    "        X_train.loc[X_train['T4_Result'] > 12.0, 'T4_Category'] = 1\n",
    "        \n",
    "        X_test['T4_Category'] = 0\n",
    "        X_test.loc[X_test['T4_Result'] < 5.0, 'T4_Category'] = -1\n",
    "        X_test.loc[X_test['T4_Result'] > 12.0, 'T4_Category'] = 1\n",
    "        \n",
    "        # T3 정상 범위: 0.8-2.0 ng/dL\n",
    "        X_train['T3_Category'] = 0\n",
    "        X_train.loc[X_train['T3_Result'] < 0.8, 'T3_Category'] = -1\n",
    "        X_train.loc[X_train['T3_Result'] > 2.0, 'T3_Category'] = 1\n",
    "        \n",
    "        X_test['T3_Category'] = 0\n",
    "        X_test.loc[X_test['T3_Result'] < 0.8, 'T3_Category'] = -1\n",
    "        X_test.loc[X_test['T3_Result'] > 2.0, 'T3_Category'] = 1\n",
    "        \n",
    "        # 호르몬 불균형 점수\n",
    "        X_train['Hormone_Imbalance'] = (\n",
    "            abs(X_train['TSH_Category']) * 0.4 +\n",
    "            abs(X_train['T4_Category']) * 0.3 +\n",
    "            abs(X_train['T3_Category']) * 0.3\n",
    "        )\n",
    "        X_test['Hormone_Imbalance'] = (\n",
    "            abs(X_test['TSH_Category']) * 0.4 +\n",
    "            abs(X_test['T4_Category']) * 0.3 +\n",
    "            abs(X_test['T3_Category']) * 0.3\n",
    "        )\n",
    "        \n",
    "        # 3. 고급 피처 엔지니어링 (H200 파워 활용)\n",
    "        print(\"  ⚡ H200 파워 고급 피처 생성...\")\n",
    "        \n",
    "        # 다항식 피처 (2차)\n",
    "        numeric_features = ['Age', 'Nodule_Size', 'TSH_Result', 'T4_Result', 'T3_Result']\n",
    "        poly = PolynomialFeatures(degree=2, include_bias=False, interaction_only=True)\n",
    "        \n",
    "        poly_train = poly.fit_transform(X_train[numeric_features])\n",
    "        poly_test = poly.transform(X_test[numeric_features])\n",
    "        \n",
    "        poly_feature_names = [f'poly_{i}' for i in range(poly_train.shape[1])]\n",
    "        \n",
    "        for i, name in enumerate(poly_feature_names):\n",
    "            X_train[name] = poly_train[:, i]\n",
    "            X_test[name] = poly_test[:, i]\n",
    "        \n",
    "        # 통계적 피처들\n",
    "        X_train['Hormone_Mean'] = (X_train['TSH_Result'] + X_train['T4_Result'] + X_train['T3_Result']) / 3\n",
    "        X_train['Hormone_Std'] = ((X_train['TSH_Result'] - X_train['Hormone_Mean'])**2 + \n",
    "                                  (X_train['T4_Result'] - X_train['Hormone_Mean'])**2 + \n",
    "                                  (X_train['T3_Result'] - X_train['Hormone_Mean'])**2)**0.5\n",
    "        \n",
    "        X_test['Hormone_Mean'] = (X_test['TSH_Result'] + X_test['T4_Result'] + X_test['T3_Result']) / 3\n",
    "        X_test['Hormone_Std'] = ((X_test['TSH_Result'] - X_test['Hormone_Mean'])**2 + \n",
    "                                 (X_test['T4_Result'] - X_test['Hormone_Mean'])**2 + \n",
    "                                 (X_test['T3_Result'] - X_test['Hormone_Mean'])**2)**0.5\n",
    "        \n",
    "        # 4. GPU 가속 특성 선택 (H200 활용)\n",
    "        if RAPIDS_AVAILABLE:\n",
    "            print(\"  🚀 RAPIDS GPU 특성 선택...\")\n",
    "            try:\n",
    "                # GPU 데이터프레임으로 변환\n",
    "                X_train_gpu = cudf.from_pandas(X_train)\n",
    "                y_train_gpu = cudf.from_pandas(y_train)\n",
    "                \n",
    "                # GPU 랜덤 포레스트로 특성 중요도 계산\n",
    "                gpu_rf = cuRF(n_estimators=100, random_state=random_seed)\n",
    "                gpu_rf.fit(X_train_gpu, y_train_gpu)\n",
    "                \n",
    "                # 중요도 상위 특성 선택\n",
    "                importances = gpu_rf.feature_importances_\n",
    "                top_features_idx = np.argsort(importances)[-30:]  # 상위 30개\n",
    "                \n",
    "                feature_names = X_train.columns\n",
    "                selected_features = feature_names[top_features_idx]\n",
    "                \n",
    "                X_train = X_train[selected_features]\n",
    "                X_test = X_test[selected_features]\n",
    "                \n",
    "                print(f\"    GPU 특성 선택 완료: {len(selected_features)}개 특성\")\n",
    "                \n",
    "            except Exception as e:\n",
    "                print(f\"    RAPIDS 특성 선택 실패: {e}\")\n",
    "        \n",
    "        return X_train, y_train, X_test, test_df['ID']\n",
    "    \n",
    "    def strategy_1_pytorch_deep_learning(self):\n",
    "        \"\"\"전략 1: PyTorch 딥러닝 (GPU 가속)\"\"\"\n",
    "        if not PYTORCH_AVAILABLE:\n",
    "            print(\"\\n❌ PyTorch 없음 - 전략 1 스킵\")\n",
    "            return None\n",
    "            \n",
    "        print(\"\\n🧠 전략 1: PyTorch 딥러닝 (H200 GPU 가속)!\")\n",
    "        \n",
    "        X_train, y_train, X_test, test_ids = self.load_and_ultimate_preprocess(42)\n",
    "        \n",
    "        # GPU 설정\n",
    "        device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "        print(f\"  디바이스: {device}\")\n",
    "        \n",
    "        # 데이터 정규화\n",
    "        scaler = StandardScaler()\n",
    "        X_train_scaled = scaler.fit_transform(X_train)\n",
    "        X_test_scaled = scaler.transform(X_test)\n",
    "        \n",
    "        # PyTorch 데이터셋 클래스\n",
    "        class ThyroidDataset(Dataset):\n",
    "            def __init__(self, X, y=None):\n",
    "                self.X = torch.FloatTensor(X)\n",
    "                self.y = torch.LongTensor(y) if y is not None else None\n",
    "                \n",
    "            def __len__(self):\n",
    "                return len(self.X)\n",
    "                \n",
    "            def __getitem__(self, idx):\n",
    "                if self.y is not None:\n",
    "                    return self.X[idx], self.y[idx]\n",
    "                return self.X[idx]\n",
    "        \n",
    "        # 딥러닝 모델 정의\n",
    "        class ThyroidNet(nn.Module):\n",
    "            def __init__(self, input_dim, hidden_dims=[512, 256, 128, 64]):\n",
    "                super(ThyroidNet, self).__init__()\n",
    "                \n",
    "                layers = []\n",
    "                prev_dim = input_dim\n",
    "                \n",
    "                for hidden_dim in hidden_dims:\n",
    "                    layers.extend([\n",
    "                        nn.Linear(prev_dim, hidden_dim),\n",
    "                        nn.BatchNorm1d(hidden_dim),\n",
    "                        nn.ReLU(),\n",
    "                        nn.Dropout(0.3)\n",
    "                    ])\n",
    "                    prev_dim = hidden_dim\n",
    "                \n",
    "                layers.append(nn.Linear(prev_dim, 2))\n",
    "                self.network = nn.Sequential(*layers)\n",
    "                \n",
    "            def forward(self, x):\n",
    "                return self.network(x)\n",
    "        \n",
    "        # 5-fold CV\n",
    "        cv = StratifiedKFold(n_splits=5, shuffle=True, random_state=42)\n",
    "        oof_predictions = np.zeros(len(X_train))\n",
    "        test_predictions = np.zeros(len(X_test))\n",
    "        \n",
    "        for fold, (train_idx, val_idx) in enumerate(cv.split(X_train_scaled, y_train)):\n",
    "            print(f\"  Fold {fold+1}/5 훈련 중...\")\n",
    "            \n",
    "            X_tr, X_val = X_train_scaled[train_idx], X_train_scaled[val_idx]\n",
    "            y_tr, y_val = y_train.iloc[train_idx], y_train.iloc[val_idx]\n",
    "            \n",
    "            # 데이터셋 및 데이터로더\n",
    "            train_dataset = ThyroidDataset(X_tr, y_tr.values)\n",
    "            val_dataset = ThyroidDataset(X_val, y_val.values)\n",
    "            \n",
    "            train_loader = DataLoader(train_dataset, batch_size=1024, shuffle=True)\n",
    "            val_loader = DataLoader(val_dataset, batch_size=1024, shuffle=False)\n",
    "            \n",
    "            # 모델 초기화\n",
    "            model = ThyroidNet(X_train_scaled.shape[1]).to(device)\n",
    "            criterion = nn.CrossEntropyLoss()\n",
    "            optimizer = optim.Adam(model.parameters(), lr=0.001, weight_decay=1e-5)\n",
    "            scheduler = optim.lr_scheduler.ReduceLROnPlateau(optimizer, patience=10)\n",
    "            \n",
    "            # 훈련\n",
    "            best_val_loss = float('inf')\n",
    "            patience_counter = 0\n",
    "            \n",
    "            for epoch in range(200):\n",
    "                # 훈련\n",
    "                model.train()\n",
    "                train_loss = 0\n",
    "                for batch_X, batch_y in train_loader:\n",
    "                    batch_X, batch_y = batch_X.to(device), batch_y.to(device)\n",
    "                    \n",
    "                    optimizer.zero_grad()\n",
    "                    outputs = model(batch_X)\n",
    "                    loss = criterion(outputs, batch_y)\n",
    "                    loss.backward()\n",
    "                    optimizer.step()\n",
    "                    \n",
    "                    train_loss += loss.item()\n",
    "                \n",
    "                # 검증\n",
    "                model.eval()\n",
    "                val_loss = 0\n",
    "                with torch.no_grad():\n",
    "                    for batch_X, batch_y in val_loader:\n",
    "                        batch_X, batch_y = batch_X.to(device), batch_y.to(device)\n",
    "                        outputs = model(batch_X)\n",
    "                        loss = criterion(outputs, batch_y)\n",
    "                        val_loss += loss.item()\n",
    "                \n",
    "                avg_val_loss = val_loss / len(val_loader)\n",
    "                scheduler.step(avg_val_loss)\n",
    "                \n",
    "                # Early stopping\n",
    "                if avg_val_loss < best_val_loss:\n",
    "                    best_val_loss = avg_val_loss\n",
    "                    patience_counter = 0\n",
    "                    # 최고 모델 저장\n",
    "                    torch.save(model.state_dict(), f'best_model_fold_{fold}.pth')\n",
    "                else:\n",
    "                    patience_counter += 1\n",
    "                    if patience_counter >= 20:\n",
    "                        break\n",
    "            \n",
    "            # 최고 모델 로드 및 예측\n",
    "            model.load_state_dict(torch.load(f'best_model_fold_{fold}.pth'))\n",
    "            model.eval()\n",
    "            \n",
    "            with torch.no_grad():\n",
    "                # OOF 예측\n",
    "                val_tensor = torch.FloatTensor(X_val).to(device)\n",
    "                val_outputs = model(val_tensor)\n",
    "                val_probs = torch.softmax(val_outputs, dim=1)[:, 1].cpu().numpy()\n",
    "                oof_predictions[val_idx] = val_probs\n",
    "                \n",
    "                # 테스트 예측\n",
    "                test_tensor = torch.FloatTensor(X_test_scaled).to(device)\n",
    "                test_outputs = model(test_tensor)\n",
    "                test_probs = torch.softmax(test_outputs, dim=1)[:, 1].cpu().numpy()\n",
    "                test_predictions += test_probs / 5\n",
    "        \n",
    "        # CV 성능 평가\n",
    "        oof_pred_binary = (oof_predictions > 0.5).astype(int)\n",
    "        cv_f1 = f1_score(y_train, oof_pred_binary)\n",
    "        print(f\"  ✅ PyTorch CV F1: {cv_f1:.6f}\")\n",
    "        \n",
    "        # 최종 예측\n",
    "        final_predictions = (test_predictions > 0.5).astype(int)\n",
    "        \n",
    "        submission = pd.DataFrame({'ID': test_ids, 'Cancer': final_predictions})\n",
    "        self.submissions['pytorch_deep'] = submission\n",
    "        return submission\n",
    "    \n",
    "    def strategy_2_gpu_mega_ensemble(self):\n",
    "        \"\"\"전략 2: GPU 메가 앙상블 (100개 모델)\"\"\"\n",
    "        print(\"\\n🔄 전략 2: GPU 메가 앙상블 (100개 모델)!\")\n",
    "        print(\"  H200 파워로 100개 모델 동시 훈련...\")\n",
    "        \n",
    "        X_train, y_train, X_test, test_ids = self.load_and_ultimate_preprocess(42)\n",
    "        \n",
    "        pos_count = (y_train == 1).sum()\n",
    "        neg_count = (y_train == 0).sum()\n",
    "        scale_pos_weight = neg_count / pos_count\n",
    "        \n",
    "        # 100개 다양한 모델 생성 (GPU 메모리 활용)\n",
    "        models = []\n",
    "        \n",
    "        print(\"  100개 모델 생성 중...\")\n",
    "        \n",
    "        # XGBoost 변형들 (40개)\n",
    "        for i in range(40):\n",
    "            seed = 42 + i * 137\n",
    "            params = {\n",
    "                'n_estimators': np.random.randint(150, 300),\n",
    "                'max_depth': np.random.randint(4, 10),\n",
    "                'learning_rate': np.random.uniform(0.03, 0.15),\n",
    "                'subsample': np.random.uniform(0.7, 1.0),\n",
    "                'colsample_bytree': np.random.uniform(0.7, 1.0),\n",
    "                'reg_alpha': np.random.uniform(0, 1.0),\n",
    "                'reg_lambda': np.random.uniform(0, 1.0),\n",
    "                'random_state': seed,\n",
    "                'scale_pos_weight': scale_pos_weight,\n",
    "                'tree_method': 'gpu_hist',  # GPU 가속\n",
    "                'gpu_id': 0,\n",
    "                'verbosity': 0\n",
    "            }\n",
    "            models.append(('xgb_' + str(i), xgb.XGBClassifier(**params)))\n",
    "        \n",
    "        # LightGBM 변형들 (30개)\n",
    "        for i in range(30):\n",
    "            seed = 42 + i * 239\n",
    "            params = {\n",
    "                'n_estimators': np.random.randint(150, 300),\n",
    "                'max_depth': np.random.randint(4, 10),\n",
    "                'learning_rate': np.random.uniform(0.03, 0.15),\n",
    "                'subsample': np.random.uniform(0.7, 1.0),\n",
    "                'colsample_bytree': np.random.uniform(0.7, 1.0),\n",
    "                'reg_alpha': np.random.uniform(0, 1.0),\n",
    "                'reg_lambda': np.random.uniform(0, 1.0),\n",
    "                'random_state': seed,\n",
    "                'class_weight': 'balanced',\n",
    "                'device': 'gpu',  # GPU 가속\n",
    "                'verbosity': -1\n",
    "            }\n",
    "            models.append(('lgb_' + str(i), lgb.LGBMClassifier(**params)))\n",
    "        \n",
    "        # CatBoost 변형들 (20개)\n",
    "        for i in range(20):\n",
    "            seed = 42 + i * 317\n",
    "            params = {\n",
    "                'iterations': np.random.randint(150, 300),\n",
    "                'depth': np.random.randint(4, 10),\n",
    "                'learning_rate': np.random.uniform(0.03, 0.15),\n",
    "                'random_state': seed,\n",
    "                'task_type': 'GPU',  # GPU 가속\n",
    "                'verbose': False\n",
    "            }\n",
    "            models.append(('cat_' + str(i), cb.CatBoostClassifier(**params)))\n",
    "        \n",
    "        # ExtraTrees 변형들 (10개)\n",
    "        for i in range(10):\n",
    "            seed = 42 + i * 419\n",
    "            params = {\n",
    "                'n_estimators': np.random.randint(200, 400),\n",
    "                'max_depth': np.random.randint(10, 20),\n",
    "                'random_state': seed,\n",
    "                'class_weight': 'balanced',\n",
    "                'n_jobs': -1\n",
    "            }\n",
    "            models.append(('et_' + str(i), ExtraTreesClassifier(**params)))\n",
    "        \n",
    "        print(f\"  총 {len(models)}개 모델 준비 완료\")\n",
    "        \n",
    "        # 스태킹 앙상블\n",
    "        cv = StratifiedKFold(n_splits=5, shuffle=True, random_state=42)\n",
    "        oof_predictions = np.zeros((len(X_train), len(models)))\n",
    "        test_predictions = np.zeros((len(X_test), len(models)))\n",
    "        \n",
    "        # 병렬 처리로 모델 훈련\n",
    "        for i, (name, model) in enumerate(models):\n",
    "            if i % 20 == 0:\n",
    "                print(f\"  모델 {i+1}/{len(models)} 훈련 중...\")\n",
    "            \n",
    "            try:\n",
    "                oof_pred = np.zeros(len(X_train))\n",
    "                \n",
    "                for train_idx, val_idx in cv.split(X_train, y_train):\n",
    "                    X_tr, X_val = X_train.iloc[train_idx], X_train.iloc[val_idx]\n",
    "                    y_tr, y_val = y_train.iloc[train_idx], y_train.iloc[val_idx]\n",
    "                    \n",
    "                    model.fit(X_tr, y_tr)\n",
    "                    oof_pred[val_idx] = model.predict_proba(X_val)[:, 1]\n",
    "                \n",
    "                oof_predictions[:, i] = oof_pred\n",
    "                model.fit(X_train, y_train)\n",
    "                test_predictions[:, i] = model.predict_proba(X_test)[:, 1]\n",
    "                \n",
    "            except Exception as e:\n",
    "                print(f\"    ❌ {name} 실패: {e}\")\n",
    "                oof_predictions[:, i] = 0.12\n",
    "                test_predictions[:, i] = 0.12\n",
    "        \n",
    "        # GPU 메타 모델 (RAPIDS)\n",
    "        if RAPIDS_AVAILABLE:\n",
    "            try:\n",
    "                print(\"  🚀 RAPIDS GPU 메타모델 훈련...\")\n",
    "                oof_gpu = cudf.from_pandas(pd.DataFrame(oof_predictions))\n",
    "                y_gpu = cudf.from_pandas(y_train)\n",
    "                \n",
    "                meta_model = cuLR(class_weight='balanced')\n",
    "                meta_model.fit(oof_gpu, y_gpu)\n",
    "                \n",
    "                test_gpu = cudf.from_pandas(pd.DataFrame(test_predictions))\n",
    "                final_proba = meta_model.predict_proba(test_gpu)[:, 1].to_array()\n",
    "                \n",
    "            except Exception as e:\n",
    "                print(f\"    RAPIDS 메타모델 실패: {e}, sklearn 사용\")\n",
    "                meta_model = LogisticRegression(random_state=42, class_weight='balanced', C=0.1)\n",
    "                meta_model.fit(oof_predictions, y_train)\n",
    "                final_proba = meta_model.predict_proba(test_predictions)[:, 1]\n",
    "        else:\n",
    "            meta_model = LogisticRegression(random_state=42, class_weight='balanced', C=0.1)\n",
    "            meta_model.fit(oof_predictions, y_train)\n",
    "            final_proba = meta_model.predict_proba(test_predictions)[:, 1]\n",
    "        \n",
    "        final_predictions = (final_proba > 0.5).astype(int)\n",
    "        \n",
    "        submission = pd.DataFrame({'ID': test_ids, 'Cancer': final_predictions})\n",
    "        self.submissions['gpu_mega_ensemble'] = submission\n",
    "        \n",
    "        print(\"  ✅ 100개 모델 GPU 앙상블 완료!\")\n",
    "        return submission\n",
    "    \n",
    "    def strategy_3_optuna_extreme_optimization(self):\n",
    "        \"\"\"전략 3: Optuna 극한 최적화 (1000회 시도)\"\"\"\n",
    "        if not OPTUNA_AVAILABLE:\n",
    "            print(\"\\n❌ Optuna 없음 - 전략 3 스킵\")\n",
    "            return None\n",
    "            \n",
    "        print(\"\\n🎯 전략 3: Optuna 극한 최적화 (1000회 시도)!\")\n",
    "        print(\"  H200 파워로 1000회 베이지안 최적화...\")\n",
    "        \n",
    "        X_train, y_train, X_test, test_ids = self.load_and_ultimate_preprocess(42)\n",
    "        \n",
    "        pos_count = (y_train == 1).sum()\n",
    "        neg_count = (y_train == 0).sum()\n",
    "        scale_pos_weight = neg_count / pos_count\n",
    "        \n",
    "        def objective(trial):\n",
    "            # 매우 세밀한 파라미터 탐색\n",
    "            params = {\n",
    "                'n_estimators': trial.suggest_int('n_estimators', 100, 500),\n",
    "                'max_depth': trial.suggest_int('max_depth', 3, 12),\n",
    "                'learning_rate': trial.suggest_float('learning_rate', 0.005, 0.3, log=True),\n",
    "                'subsample': trial.suggest_float('subsample', 0.5, 1.0),\n",
    "                'colsample_bytree': trial.suggest_float('colsample_bytree', 0.5, 1.0),\n",
    "                'reg_alpha': trial.suggest_float('reg_alpha', 0, 2.0),\n",
    "                'reg_lambda': trial.suggest_float('reg_lambda', 0, 2.0),\n",
    "                'min_child_weight': trial.suggest_int('min_child_weight', 1, 10),\n",
    "                'gamma': trial.suggest_float('gamma', 0, 2.0),\n",
    "                'random_state': 42,\n",
    "                'scale_pos_weight': scale_pos_weight,\n",
    "                'tree_method': 'gpu_hist',\n",
    "                'gpu_id': 0,\n",
    "                'verbosity': 0\n",
    "            }\n",
    "            \n",
    "            model = xgb.XGBClassifier(**params)\n",
    "            \n",
    "            # 빠른 CV (3-fold)\n",
    "            cv = StratifiedKFold(n_splits=3, shuffle=True, random_state=42)\n",
    "            cv_scores = cross_val_score(model, X_train, y_train, cv=cv, scoring='f1', n_jobs=1)\n",
    "            \n",
    "            return cv_scores.mean()\n",
    "        \n",
    "        try:\n",
    "            # Optuna 연구 생성\n",
    "            study = optuna.create_study(\n",
    "                direction='maximize',\n",
    "                pruner=optuna.pruners.MedianPruner(n_startup_trials=50, n_warmup_steps=10)\n",
    "            )\n",
    "            \n",
    "            # 1000회 최적화 (H200 파워로!)\n",
    "            study.optimize(objective, n_trials=1000, timeout=3600)  # 1시간 한도\n",
    "            \n",
    "            best_params = study.best_params\n",
    "            best_score = study.best_value\n",
    "            \n",
    "            print(f\"  ✅ Optuna 최고 점수: {best_score:.6f}\")\n",
    "            print(f\"  최적 파라미터: {best_params}\")\n",
    "            \n",
    "            # 최적 파라미터로 스태킹 앙상블\n",
    "            models = {\n",
    "                'xgb_optimized': xgb.XGBClassifier(**best_params),\n",
    "                'lgb_baseline': lgb.LGBMClassifier(n_estimators=200, max_depth=6, learning_rate=0.08, random_state=42, class_weight='balanced', device='gpu', verbosity=-1),\n",
    "                'cat_baseline': cb.CatBoostClassifier(iterations=200, depth=6, learning_rate=0.08, random_state=42, task_type='GPU', verbose=False)\n",
    "            }\n",
    "            \n",
    "            cv = StratifiedKFold(n_splits=5, shuffle=True, random_state=42)\n",
    "            oof_predictions = np.zeros((len(X_train), len(models)))\n",
    "            test_predictions = np.zeros((len(X_test), len(models)))\n",
    "            \n",
    "            for i, (name, model) in enumerate(models.items()):\n",
    "                print(f\"  {name} 훈련 중...\")\n",
    "                oof_pred = np.zeros(len(X_train))\n",
    "                \n",
    "                for train_idx, val_idx in cv.split(X_train, y_train):\n",
    "                    X_tr, X_val = X_train.iloc[train_idx], X_train.iloc[val_idx]\n",
    "                    y_tr, y_val = y_train.iloc[train_idx], y_train.iloc[val_idx]\n",
    "                    \n",
    "                    model.fit(X_tr, y_tr)\n",
    "                    oof_pred[val_idx] = model.predict_proba(X_val)[:, 1]\n",
    "                \n",
    "                oof_predictions[:, i] = oof_pred\n",
    "                model.fit(X_train, y_train)\n",
    "                test_predictions[:, i] = model.predict_proba(X_test)[:, 1]\n",
    "            \n",
    "            # 메타 모델\n",
    "            meta_model = LogisticRegression(random_state=42, class_weight='balanced', C=0.1)\n",
    "            meta_model.fit(oof_predictions, y_train)\n",
    "            \n",
    "            final_proba = meta_model.predict_proba(test_predictions)[:, 1]\n",
    "            final_predictions = (final_proba > 0.5).astype(int)\n",
    "            \n",
    "            submission = pd.DataFrame({'ID': test_ids, 'Cancer': final_predictions})\n",
    "            self.submissions['optuna_extreme'] = submission\n",
    "            return submission\n",
    "            \n",
    "        except Exception as e:\n",
    "            print(f\"  ❌ Optuna 극한 최적화 실패: {e}\")\n",
    "            return None\n",
    "    \n",
    "    def strategy_4_h200_ultimate_fusion(self):\n",
    "        \"\"\"전략 4: H200 궁극 퓨전\"\"\"\n",
    "        print(\"\\n👹 전략 4: H200 궁극 퓨전!\")\n",
    "        \n",
    "        if len(self.submissions) < 2:\n",
    "            print(\"  충분한 전략이 실행되지 않음\")\n",
    "            return None\n",
    "        \n",
    "        # 가중치 (GPU 기반 전략들에 더 높은 가중치)\n",
    "        strategy_weights = {\n",
    "            'pytorch_deep': 1.5,        # 딥러닝\n",
    "            'gpu_mega_ensemble': 1.6,   # 가장 높은 가중치\n",
    "            'optuna_extreme': 1.4,      # 극한 최적화\n",
    "        }\n",
    "        \n",
    "        weights = []\n",
    "        predictions = []\n",
    "        \n",
    "        for name, submission in self.submissions.items():\n",
    "            if name in strategy_weights:\n",
    "                predictions.append(submission['Cancer'].values)\n",
    "                weights.append(strategy_weights[name])\n",
    "                print(f\"  {name}: 가중치 {strategy_weights[name]}\")\n",
    "        \n",
    "        if len(predictions) == 0:\n",
    "            print(\"  유효한 전략이 없음\")\n",
    "            return None\n",
    "        \n",
    "        # 가중 평균\n",
    "        weighted_avg = np.average(predictions, axis=0, weights=weights)\n",
    "        \n",
    "        # 임계값 미세 조정\n",
    "        thresholds = np.arange(0.45, 0.55, 0.001)\n",
    "        best_threshold = 0.5\n",
    "        \n",
    "        for threshold in thresholds:\n",
    "            final_predictions = (weighted_avg >= threshold).astype(int)\n",
    "            pred_ratio = final_predictions.mean()\n",
    "            \n",
    "            # 12% ± 0.3% 범위 내에서 선택\n",
    "            if abs(pred_ratio - 0.12) < 0.003:\n",
    "                best_threshold = threshold\n",
    "                print(f\"  ✅ 임계값 {threshold:.3f} 선택 (비율: {pred_ratio:.4f})\")\n",
    "                break\n",
    "        \n",
    "        final_predictions = (weighted_avg >= best_threshold).astype(int)\n",
    "        \n",
    "        test_ids = list(self.submissions.values())[0]['ID']\n",
    "        submission = pd.DataFrame({'ID': test_ids, 'Cancer': final_predictions})\n",
    "        \n",
    "        self.submissions['h200_ultimate'] = submission\n",
    "        return submission\n",
    "\n",
    "def run_h200_monster_hunt():\n",
    "    \"\"\"H200 괴물 사냥 실행\"\"\"\n",
    "    print(\"👹 H200 GPU 풀파워 괴물 사냥!\")\n",
    "    print(\"=\" * 60)\n",
    "    print(\"🔥 NVIDIA H200 + 140GB 메모리 풀가동!\")\n",
    "    print(\"🎯 목표: 0.5120+ (괴물 완전 제압!)\")\n",
    "    print(\"⚡ GPU 가속 딥러닝 + 메가 앙상블 + 극한 최적화\")\n",
    "    print(\"=\" * 60)\n",
    "    \n",
    "    start_time = time.time()\n",
    "    killer = H200MonsterKiller()\n",
    "    \n",
    "    strategies = [\n",
    "        (\"PyTorch 딥러닝\", killer.strategy_1_pytorch_deep_learning),\n",
    "        (\"GPU 메가 앙상블\", killer.strategy_2_gpu_mega_ensemble),\n",
    "        (\"Optuna 극한 최적화\", killer.strategy_3_optuna_extreme_optimization),\n",
    "        (\"H200 궁극 퓨전\", killer.strategy_4_h200_ultimate_fusion)\n",
    "    ]\n",
    "    \n",
    "    for i, (name, strategy_func) in enumerate(strategies, 1):\n",
    "        print(f\"\\n{'='*20} {name} {'='*20}\")\n",
    "        strategy_start = time.time()\n",
    "        \n",
    "        try:\n",
    "            result = strategy_func()\n",
    "            if result is not None:\n",
    "                filename = f'h200_kill_{i}.csv'\n",
    "                result.to_csv(filename, index=False)\n",
    "                print(f\"  💾 저장: {filename}\")\n",
    "        except Exception as e:\n",
    "            print(f\"  ❌ {name} 실패: {e}\")\n",
    "        \n",
    "        strategy_time = time.time() - strategy_start\n",
    "        print(f\"  ⏱️ 소요 시간: {strategy_time:.1f}초\")\n",
    "    \n",
    "    # 최종 H200 킬러\n",
    "    if 'h200_ultimate' in killer.submissions:\n",
    "        best_submission = killer.submissions['h200_ultimate']\n",
    "        best_submission.to_csv('H200_MONSTER_DESTROYER.csv', index=False)\n",
    "        print(f\"\\n👹 H200 괴물 파괴자: H200_MONSTER_DESTROYER.csv\")\n",
    "    \n",
    "    total_time = time.time() - start_time\n",
    "    \n",
    "    print(f\"\\n🏆 H200 작전 완료!\")\n",
    "    print(f\"⏱️ 총 소요 시간: {total_time:.1f}초\")\n",
    "    print(f\"🔥 GPU 파워: 100% 활용\")\n",
    "    print(f\"📁 생성된 파일:\")\n",
    "    print(f\"  1. H200_MONSTER_DESTROYER.csv ⭐ (최종 보스)\")\n",
    "    print(f\"  2. h200_kill_2.csv (100개 모델 메가 앙상블)\")\n",
    "    print(f\"  3. h200_kill_1.csv (PyTorch 딥러닝)\")\n",
    "    print(f\"  4. h200_kill_3.csv (1000회 Optuna)\")\n",
    "    \n",
    "    print(f\"\\n🎯 기대 결과:\")\n",
    "    print(f\"  - 0.5112+: GPU 딥러닝 효과!\")\n",
    "    print(f\"  - 0.5116+: 메가 앙상블 파워!\")\n",
    "    print(f\"  - 0.5120+: 진짜 괴물 완전 제압! 👹💀\")\n",
    "    \n",
    "    print(f\"\\n🔥 H200의 진짜 파워를 보여줬습니다!\")\n",
    "    print(f\"💪 140GB 메모리 + GPU 가속으로 모든 걸 시도했습니다!\")\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    run_h200_monster_hunt()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
