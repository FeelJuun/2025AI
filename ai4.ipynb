{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "b4b3d026-261c-41ae-a006-7c3f7e98f326",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üéØ ÌäπÏÑ± Ï§ëÏöîÎèÑ Í∏∞Î∞ò Îã®ÏàúÌôî Ï†ÑÎûµ!\n",
      "Î≥µÏû°Ìïú Í≤ÉÎ≥¥Îã§ Îã®ÏàúÌïú Í≤ÉÏù¥ ÎïåÎ°úÎäî Îçî Ï¢ãÏäµÎãàÎã§!\n",
      "============================================================\n",
      "üìä ÏõêÎ≥∏ ÌäπÏÑ± Í∞úÏàò: 14\n",
      "   ÌäπÏÑ± Î™©Î°ù: ['Age', 'Gender', 'Country', 'Race', 'Family_Background', 'Radiation_History', 'Iodine_Deficiency', 'Smoke', 'Weight_Risk', 'Diabetes', 'Nodule_Size', 'TSH_Result', 'T4_Result', 'T3_Result']\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_1149/271349957.py:61: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
      "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
      "\n",
      "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
      "\n",
      "\n",
      "  X_train[col].fillna(median_val, inplace=True)\n",
      "/tmp/ipykernel_1149/271349957.py:62: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
      "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
      "\n",
      "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
      "\n",
      "\n",
      "  X_test[col].fillna(median_val, inplace=True)\n",
      "/tmp/ipykernel_1149/271349957.py:61: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
      "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
      "\n",
      "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
      "\n",
      "\n",
      "  X_train[col].fillna(median_val, inplace=True)\n",
      "/tmp/ipykernel_1149/271349957.py:62: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
      "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
      "\n",
      "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
      "\n",
      "\n",
      "  X_test[col].fillna(median_val, inplace=True)\n",
      "/tmp/ipykernel_1149/271349957.py:61: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
      "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
      "\n",
      "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
      "\n",
      "\n",
      "  X_train[col].fillna(median_val, inplace=True)\n",
      "/tmp/ipykernel_1149/271349957.py:62: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
      "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
      "\n",
      "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
      "\n",
      "\n",
      "  X_test[col].fillna(median_val, inplace=True)\n",
      "/tmp/ipykernel_1149/271349957.py:61: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
      "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
      "\n",
      "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
      "\n",
      "\n",
      "  X_train[col].fillna(median_val, inplace=True)\n",
      "/tmp/ipykernel_1149/271349957.py:62: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
      "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
      "\n",
      "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
      "\n",
      "\n",
      "  X_test[col].fillna(median_val, inplace=True)\n",
      "/tmp/ipykernel_1149/271349957.py:61: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
      "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
      "\n",
      "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
      "\n",
      "\n",
      "  X_train[col].fillna(median_val, inplace=True)\n",
      "/tmp/ipykernel_1149/271349957.py:62: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
      "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
      "\n",
      "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
      "\n",
      "\n",
      "  X_test[col].fillna(median_val, inplace=True)\n",
      "/tmp/ipykernel_1149/271349957.py:61: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
      "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
      "\n",
      "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
      "\n",
      "\n",
      "  X_train[col].fillna(median_val, inplace=True)\n",
      "/tmp/ipykernel_1149/271349957.py:62: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
      "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
      "\n",
      "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
      "\n",
      "\n",
      "  X_test[col].fillna(median_val, inplace=True)\n",
      "/tmp/ipykernel_1149/271349957.py:61: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
      "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
      "\n",
      "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
      "\n",
      "\n",
      "  X_train[col].fillna(median_val, inplace=True)\n",
      "/tmp/ipykernel_1149/271349957.py:62: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
      "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
      "\n",
      "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
      "\n",
      "\n",
      "  X_test[col].fillna(median_val, inplace=True)\n",
      "/tmp/ipykernel_1149/271349957.py:61: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
      "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
      "\n",
      "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
      "\n",
      "\n",
      "  X_train[col].fillna(median_val, inplace=True)\n",
      "/tmp/ipykernel_1149/271349957.py:62: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
      "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
      "\n",
      "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
      "\n",
      "\n",
      "  X_test[col].fillna(median_val, inplace=True)\n",
      "/tmp/ipykernel_1149/271349957.py:61: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
      "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
      "\n",
      "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
      "\n",
      "\n",
      "  X_train[col].fillna(median_val, inplace=True)\n",
      "/tmp/ipykernel_1149/271349957.py:62: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
      "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
      "\n",
      "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
      "\n",
      "\n",
      "  X_test[col].fillna(median_val, inplace=True)\n",
      "/tmp/ipykernel_1149/271349957.py:61: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
      "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
      "\n",
      "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
      "\n",
      "\n",
      "  X_train[col].fillna(median_val, inplace=True)\n",
      "/tmp/ipykernel_1149/271349957.py:62: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
      "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
      "\n",
      "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
      "\n",
      "\n",
      "  X_test[col].fillna(median_val, inplace=True)\n",
      "/tmp/ipykernel_1149/271349957.py:61: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
      "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
      "\n",
      "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
      "\n",
      "\n",
      "  X_train[col].fillna(median_val, inplace=True)\n",
      "/tmp/ipykernel_1149/271349957.py:62: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
      "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
      "\n",
      "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
      "\n",
      "\n",
      "  X_test[col].fillna(median_val, inplace=True)\n",
      "/tmp/ipykernel_1149/271349957.py:61: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
      "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
      "\n",
      "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
      "\n",
      "\n",
      "  X_train[col].fillna(median_val, inplace=True)\n",
      "/tmp/ipykernel_1149/271349957.py:62: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
      "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
      "\n",
      "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
      "\n",
      "\n",
      "  X_test[col].fillna(median_val, inplace=True)\n",
      "/tmp/ipykernel_1149/271349957.py:61: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
      "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
      "\n",
      "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
      "\n",
      "\n",
      "  X_train[col].fillna(median_val, inplace=True)\n",
      "/tmp/ipykernel_1149/271349957.py:62: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
      "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
      "\n",
      "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
      "\n",
      "\n",
      "  X_test[col].fillna(median_val, inplace=True)\n",
      "/tmp/ipykernel_1149/271349957.py:61: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
      "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
      "\n",
      "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
      "\n",
      "\n",
      "  X_train[col].fillna(median_val, inplace=True)\n",
      "/tmp/ipykernel_1149/271349957.py:62: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
      "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
      "\n",
      "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
      "\n",
      "\n",
      "  X_test[col].fillna(median_val, inplace=True)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "üîç ÌäπÏÑ± Ï§ëÏöîÎèÑ Î∂ÑÏÑù Ï§ë...\n",
      "  XGBoost Ï§ëÏöîÎèÑ Í≥ÑÏÇ∞...\n",
      "  LightGBM Ï§ëÏöîÎèÑ Í≥ÑÏÇ∞...\n",
      "  Random Forest Ï§ëÏöîÎèÑ Í≥ÑÏÇ∞...\n",
      "  F-test Ï§ëÏöîÎèÑ Í≥ÑÏÇ∞...\n",
      "  Mutual Information Í≥ÑÏÇ∞...\n",
      "\n",
      "üìä ÌäπÏÑ± Ï§ëÏöîÎèÑ ÏàúÏúÑ:\n",
      "  T4_Result           : 94.0161 (XGB: 0.015, LGB: 470.000, RF: 0.032)\n",
      "  Nodule_Size         : 88.0271 (XGB: 0.015, LGB: 440.000, RF: 0.028)\n",
      "  T3_Result           : 85.6091 (XGB: 0.014, LGB: 428.000, RF: 0.030)\n",
      "  TSH_Result          : 84.2101 (XGB: 0.014, LGB: 421.000, RF: 0.031)\n",
      "  Age                 : 70.2214 (XGB: 0.013, LGB: 351.000, RF: 0.023)\n",
      "  Country             : 63.0974 (XGB: 0.097, LGB: 315.000, RF: 0.130)\n",
      "  Race                : 40.9458 (XGB: 0.201, LGB: 203.000, RF: 0.315)\n",
      "  Iodine_Deficiency   : 19.9541 (XGB: 0.109, LGB: 98.000, RF: 0.108)\n",
      "  Radiation_History   : 17.5171 (XGB: 0.166, LGB: 86.000, RF: 0.098)\n",
      "  Family_Background   : 13.7938 (XGB: 0.303, LGB: 67.000, RF: 0.193)\n",
      "  Weight_Risk         : 8.0395 (XGB: 0.014, LGB: 40.000, RF: 0.003)\n",
      "  Gender              : 7.0771 (XGB: 0.014, LGB: 35.000, RF: 0.003)\n",
      "  Diabetes            : 4.8137 (XGB: 0.014, LGB: 24.000, RF: 0.003)\n",
      "  Smoke               : 4.4030 (XGB: 0.012, LGB: 22.000, RF: 0.003)\n",
      "\n",
      "üß™ Îã§ÏñëÌïú ÌäπÏÑ± Ï°∞Ìï© ÌÖåÏä§Ìä∏...\n",
      "\n",
      "  ÏÉÅÏúÑ 5Í∞ú ÌäπÏÑ±ÏúºÎ°ú ÌÖåÏä§Ìä∏...\n",
      "    ÏÑ†ÌÉùÎêú ÌäπÏÑ±: ['T4_Result', 'Nodule_Size', 'T3_Result', 'TSH_Result', 'Age']\n",
      "    CV F1: 0.176965 ¬± 0.000627\n",
      "\n",
      "  ÏÉÅÏúÑ 7Í∞ú ÌäπÏÑ±ÏúºÎ°ú ÌÖåÏä§Ìä∏...\n",
      "    ÏÑ†ÌÉùÎêú ÌäπÏÑ±: ['T4_Result', 'Nodule_Size', 'T3_Result', 'TSH_Result', 'Age', 'Country', 'Race']\n",
      "    CV F1: 0.257733 ¬± 0.003986\n",
      "\n",
      "  ÏÉÅÏúÑ 8Í∞ú ÌäπÏÑ±ÏúºÎ°ú ÌÖåÏä§Ìä∏...\n",
      "    ÏÑ†ÌÉùÎêú ÌäπÏÑ±: ['T4_Result', 'Nodule_Size', 'T3_Result', 'TSH_Result', 'Age', 'Country', 'Race', 'Iodine_Deficiency']\n",
      "    CV F1: 0.284539 ¬± 0.001937\n",
      "\n",
      "  ÏÉÅÏúÑ 10Í∞ú ÌäπÏÑ±ÏúºÎ°ú ÌÖåÏä§Ìä∏...\n",
      "    ÏÑ†ÌÉùÎêú ÌäπÏÑ±: ['T4_Result', 'Nodule_Size', 'T3_Result', 'TSH_Result', 'Age', 'Country', 'Race', 'Iodine_Deficiency', 'Radiation_History', 'Family_Background']\n",
      "    CV F1: 0.466447 ¬± 0.004504\n",
      "\n",
      "  ÏÉÅÏúÑ 12Í∞ú ÌäπÏÑ±ÏúºÎ°ú ÌÖåÏä§Ìä∏...\n",
      "    ÏÑ†ÌÉùÎêú ÌäπÏÑ±: ['T4_Result', 'Nodule_Size', 'T3_Result', 'TSH_Result', 'Age', 'Country', 'Race', 'Iodine_Deficiency', 'Radiation_History', 'Family_Background', 'Weight_Risk', 'Gender']\n",
      "    CV F1: 0.467680 ¬± 0.004291\n",
      "\n",
      "‚úÖ ÏµúÍ≥† ÏÑ±Îä•: 12Í∞ú ÌäπÏÑ± (CV F1: 0.467680)\n",
      "   ÏÑ†ÌÉùÎêú ÌäπÏÑ±: ['T4_Result', 'Nodule_Size', 'T3_Result', 'TSH_Result', 'Age', 'Country', 'Race', 'Iodine_Deficiency', 'Radiation_History', 'Family_Background', 'Weight_Risk', 'Gender']\n",
      "\n",
      "ü§ñ ÏÑ†ÌÉùÎêú 12Í∞ú ÌäπÏÑ±ÏúºÎ°ú ÏïôÏÉÅÎ∏î...\n",
      "  xgb_conservative: CV F1 = 0.473512\n",
      "  xgb_balanced: CV F1 = 0.468679\n",
      "  lgb: CV F1 = 0.474480\n",
      "  rf: CV F1 = 0.448857\n",
      "  Í∞ÄÏ§ëÏπò: {'xgb_conservative': np.float64(0.2538221819282609), 'xgb_balanced': np.float64(0.25123108177465553), 'lgb': np.float64(0.25434083317321105), 'rf': np.float64(0.2406059031238726)}\n",
      "\n",
      "üéØ Í∑πÎã®Ï†Å Îã®ÏàúÌôî: ÏÉÅÏúÑ 5Í∞ú ÌäπÏÑ±Îßå ÏÇ¨Ïö©\n",
      "   ÏÇ¨Ïö© ÌäπÏÑ±: ['T4_Result', 'Nodule_Size', 'T3_Result', 'TSH_Result', 'Age']\n",
      "   CV F1: 0.185359 ¬± 0.005683\n",
      "\n",
      "üíæ Ï†úÏ∂ú ÌååÏùº Ï†ÄÏû•...\n",
      "  feature_selected_best.csv: ÏµúÏ†Å ÌäπÏÑ± Ï°∞Ìï©\n",
      "    ÏòàÏ∏° Î∂ÑÌè¨ - 0: 40051, 1: 6153\n",
      "  feature_ensemble.csv: ÏÑ†ÌÉùÎêú ÌäπÏÑ± ÏïôÏÉÅÎ∏î\n",
      "    ÏòàÏ∏° Î∂ÑÌè¨ - 0: 40331, 1: 5873\n",
      "  ultra_simple.csv: Í∑πÎã®Ï†Å Îã®ÏàúÌôî\n",
      "    ÏòàÏ∏° Î∂ÑÌè¨ - 0: 25327, 1: 20877\n",
      "\n",
      "üéØ Ï†úÏ∂ú Ïö∞ÏÑ†ÏàúÏúÑ:\n",
      "1. feature_ensemble.csv ‚≠ê (ÏÑ†ÌÉùÎêú ÌäπÏÑ± ÏïôÏÉÅÎ∏î)\n",
      "2. feature_selected_best.csv (ÏµúÏ†Å ÌäπÏÑ± Ï°∞Ìï©)\n",
      "3. ultra_simple.csv (Í∑πÎã®Ï†Å Îã®ÏàúÌôî)\n",
      "\n",
      "üí° ÌïµÏã¨ ÏïÑÏù¥ÎîîÏñ¥:\n",
      "- Ï§ëÏöîÌïòÏßÄ ÏïäÏùÄ ÌäπÏÑ±Îì§Ïù¥ ÎÖ∏Ïù¥Ï¶àÎ•º ÎßåÎì§ Ïàò ÏûàÏùå\n",
      "- Îã®ÏàúÌïú Î™®Îç∏Ïù¥ ÏùºÎ∞òÌôî ÏÑ±Îä•Ïù¥ Îçî Ï¢ãÏùÑ Ïàò ÏûàÏùå\n",
      "- Í≥ºÏ†ÅÌï©ÏùÑ Ï§ÑÏó¨ÏÑú Ïã§Ï†ú ÏÑ±Îä• Ìñ•ÏÉÅ Í∞ÄÎä•\n",
      "\n",
      "üìä ÌäπÏÑ± Ï§ëÏöîÎèÑ Î∂ÑÏÑù ÏôÑÎ£å!\n",
      "ÏÉÅÏúÑ ÌäπÏÑ±Îì§: ['T4_Result', 'Nodule_Size', 'T3_Result', 'TSH_Result', 'Age', 'Country', 'Race', 'Iodine_Deficiency', 'Radiation_History', 'Family_Background', 'Weight_Risk', 'Gender']\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import StratifiedKFold, cross_val_score\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.metrics import f1_score\n",
    "import xgboost as xgb\n",
    "import lightgbm as lgb\n",
    "import catboost as cb\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.feature_selection import SelectKBest, f_classif, mutual_info_classif\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "class FeatureImportanceAnalyzer:\n",
    "    \"\"\"ÌäπÏÑ± Ï§ëÏöîÎèÑ Î∂ÑÏÑù Î∞è ÏÑ†ÌÉù Í∏∞Î∞ò ÏµúÏ†ÅÌôî\"\"\"\n",
    "    \n",
    "    def __init__(self):\n",
    "        self.feature_importances = {}\n",
    "        self.selected_features = {}\n",
    "        self.submissions = {}\n",
    "        \n",
    "    def load_and_preprocess(self, random_seed=42):\n",
    "        \"\"\"Í∏∞Î≥∏ Ï†ÑÏ≤òÎ¶¨\"\"\"\n",
    "        np.random.seed(random_seed)\n",
    "        \n",
    "        train_df = pd.read_csv('train.csv')\n",
    "        test_df = pd.read_csv('test.csv')\n",
    "        \n",
    "        feature_cols = [col for col in train_df.columns if col not in ['ID', 'Cancer']]\n",
    "        \n",
    "        X_train = train_df[feature_cols].copy()\n",
    "        y_train = train_df['Cancer'].copy()\n",
    "        X_test = test_df[feature_cols].copy()\n",
    "        \n",
    "        print(f\"üìä ÏõêÎ≥∏ ÌäπÏÑ± Í∞úÏàò: {len(feature_cols)}\")\n",
    "        print(f\"   ÌäπÏÑ± Î™©Î°ù: {feature_cols}\")\n",
    "        \n",
    "        # Ïπ¥ÌÖåÍ≥†Î¶¨Ïª¨ Ïù∏ÏΩîÎî©\n",
    "        categorical_cols = X_train.select_dtypes(include=['object']).columns\n",
    "        label_encoders = {}\n",
    "        \n",
    "        for col in categorical_cols:\n",
    "            le = LabelEncoder()\n",
    "            X_train[col] = le.fit_transform(X_train[col].astype(str))\n",
    "            label_encoders[col] = le\n",
    "            \n",
    "            test_values = X_test[col].astype(str)\n",
    "            test_encoded = []\n",
    "            for val in test_values:\n",
    "                if val in le.classes_:\n",
    "                    test_encoded.append(le.transform([val])[0])\n",
    "                else:\n",
    "                    test_encoded.append(0)\n",
    "            X_test[col] = test_encoded\n",
    "        \n",
    "        # Í≤∞Ï∏°Í∞í Ï≤òÎ¶¨\n",
    "        numeric_cols = X_train.select_dtypes(include=[np.number]).columns\n",
    "        for col in numeric_cols:\n",
    "            median_val = X_train[col].median()\n",
    "            X_train[col].fillna(median_val, inplace=True)\n",
    "            X_test[col].fillna(median_val, inplace=True)\n",
    "        \n",
    "        return X_train, y_train, X_test, test_df['ID'], feature_cols\n",
    "    \n",
    "    def analyze_feature_importance(self, X_train, y_train, feature_cols):\n",
    "        \"\"\"Îã§ÏñëÌïú Î∞©Î≤ïÏúºÎ°ú ÌäπÏÑ± Ï§ëÏöîÎèÑ Î∂ÑÏÑù\"\"\"\n",
    "        print(\"\\nüîç ÌäπÏÑ± Ï§ëÏöîÎèÑ Î∂ÑÏÑù Ï§ë...\")\n",
    "        \n",
    "        pos_count = (y_train == 1).sum()\n",
    "        neg_count = (y_train == 0).sum()\n",
    "        scale_pos_weight = neg_count / pos_count\n",
    "        \n",
    "        # 1. XGBoost Ï§ëÏöîÎèÑ\n",
    "        print(\"  XGBoost Ï§ëÏöîÎèÑ Í≥ÑÏÇ∞...\")\n",
    "        xgb_model = xgb.XGBClassifier(\n",
    "            n_estimators=100,\n",
    "            max_depth=6,\n",
    "            learning_rate=0.1,\n",
    "            random_state=42,\n",
    "            scale_pos_weight=scale_pos_weight\n",
    "        )\n",
    "        xgb_model.fit(X_train, y_train)\n",
    "        xgb_importance = xgb_model.feature_importances_\n",
    "        \n",
    "        # 2. LightGBM Ï§ëÏöîÎèÑ  \n",
    "        print(\"  LightGBM Ï§ëÏöîÎèÑ Í≥ÑÏÇ∞...\")\n",
    "        lgb_model = lgb.LGBMClassifier(\n",
    "            n_estimators=100,\n",
    "            max_depth=6,\n",
    "            learning_rate=0.1,\n",
    "            random_state=42,\n",
    "            class_weight='balanced',\n",
    "            verbose=-1\n",
    "        )\n",
    "        lgb_model.fit(X_train, y_train)\n",
    "        lgb_importance = lgb_model.feature_importances_\n",
    "        \n",
    "        # 3. Random Forest Ï§ëÏöîÎèÑ\n",
    "        print(\"  Random Forest Ï§ëÏöîÎèÑ Í≥ÑÏÇ∞...\")\n",
    "        rf_model = RandomForestClassifier(\n",
    "            n_estimators=100,\n",
    "            max_depth=8,\n",
    "            random_state=42,\n",
    "            class_weight='balanced'\n",
    "        )\n",
    "        rf_model.fit(X_train, y_train)\n",
    "        rf_importance = rf_model.feature_importances_\n",
    "        \n",
    "        # 4. ÌÜµÍ≥ÑÏ†Å Î∞©Î≤ï (F-test)\n",
    "        print(\"  F-test Ï§ëÏöîÎèÑ Í≥ÑÏÇ∞...\")\n",
    "        f_selector = SelectKBest(f_classif, k='all')\n",
    "        f_selector.fit(X_train, y_train)\n",
    "        f_scores = f_selector.scores_\n",
    "        f_importance = f_scores / f_scores.max()  # Ï†ïÍ∑úÌôî\n",
    "        \n",
    "        # 5. Mutual Information\n",
    "        print(\"  Mutual Information Í≥ÑÏÇ∞...\")\n",
    "        mi_scores = mutual_info_classif(X_train, y_train, random_state=42)\n",
    "        mi_importance = mi_scores / mi_scores.max()  # Ï†ïÍ∑úÌôî\n",
    "        \n",
    "        # Î™®Îì† Ï§ëÏöîÎèÑ Ï†ÄÏû•\n",
    "        self.feature_importances = {\n",
    "            'XGBoost': xgb_importance,\n",
    "            'LightGBM': lgb_importance,\n",
    "            'RandomForest': rf_importance,\n",
    "            'F_test': f_importance,\n",
    "            'MutualInfo': mi_importance\n",
    "        }\n",
    "        \n",
    "        # Ï§ëÏöîÎèÑ Îç∞Ïù¥ÌÑ∞ÌîÑÎ†àÏûÑ ÏÉùÏÑ±\n",
    "        importance_df = pd.DataFrame({\n",
    "            'Feature': feature_cols,\n",
    "            'XGBoost': xgb_importance,\n",
    "            'LightGBM': lgb_importance,\n",
    "            'RandomForest': rf_importance,\n",
    "            'F_test': f_importance,\n",
    "            'MutualInfo': mi_importance\n",
    "        })\n",
    "        \n",
    "        # ÌèâÍ∑† Ï§ëÏöîÎèÑ Í≥ÑÏÇ∞\n",
    "        importance_df['Average'] = importance_df[['XGBoost', 'LightGBM', 'RandomForest', 'F_test', 'MutualInfo']].mean(axis=1)\n",
    "        importance_df = importance_df.sort_values('Average', ascending=False)\n",
    "        \n",
    "        print(\"\\nüìä ÌäπÏÑ± Ï§ëÏöîÎèÑ ÏàúÏúÑ:\")\n",
    "        for i, row in importance_df.iterrows():\n",
    "            print(f\"  {row['Feature']:20s}: {row['Average']:.4f} (XGB: {row['XGBoost']:.3f}, LGB: {row['LightGBM']:.3f}, RF: {row['RandomForest']:.3f})\")\n",
    "        \n",
    "        return importance_df\n",
    "    \n",
    "    def test_feature_combinations(self, X_train, y_train, X_test, test_ids, importance_df):\n",
    "        \"\"\"Îã§ÏñëÌïú ÌäπÏÑ± Ï°∞Ìï© ÌÖåÏä§Ìä∏\"\"\"\n",
    "        print(\"\\nüß™ Îã§ÏñëÌïú ÌäπÏÑ± Ï°∞Ìï© ÌÖåÏä§Ìä∏...\")\n",
    "        \n",
    "        pos_count = (y_train == 1).sum()\n",
    "        neg_count = (y_train == 0).sum()\n",
    "        scale_pos_weight = neg_count / pos_count\n",
    "        \n",
    "        # ÌÖåÏä§Ìä∏Ìï† ÌäπÏÑ± Í∞úÏàòÎì§\n",
    "        feature_counts = [5, 7, 8, 10, 12]\n",
    "        \n",
    "        cv = StratifiedKFold(n_splits=5, shuffle=True, random_state=42)\n",
    "        \n",
    "        best_score = 0\n",
    "        best_features = None\n",
    "        best_count = 0\n",
    "        best_predictions = None\n",
    "        \n",
    "        for k in feature_counts:\n",
    "            print(f\"\\n  ÏÉÅÏúÑ {k}Í∞ú ÌäπÏÑ±ÏúºÎ°ú ÌÖåÏä§Ìä∏...\")\n",
    "            \n",
    "            # ÏÉÅÏúÑ kÍ∞ú ÌäπÏÑ± ÏÑ†ÌÉù\n",
    "            top_features = importance_df.head(k)['Feature'].tolist()\n",
    "            print(f\"    ÏÑ†ÌÉùÎêú ÌäπÏÑ±: {top_features}\")\n",
    "            \n",
    "            X_train_selected = X_train[top_features]\n",
    "            X_test_selected = X_test[top_features]\n",
    "            \n",
    "            # XGBoostÎ°ú ÏÑ±Îä• ÌÖåÏä§Ìä∏\n",
    "            model = xgb.XGBClassifier(\n",
    "                n_estimators=150,\n",
    "                max_depth=6,\n",
    "                learning_rate=0.08,\n",
    "                subsample=0.8,\n",
    "                colsample_bytree=0.8,\n",
    "                random_state=42,\n",
    "                scale_pos_weight=scale_pos_weight,\n",
    "                reg_alpha=0.1,\n",
    "                reg_lambda=0.1\n",
    "            )\n",
    "            \n",
    "            # Cross Validation\n",
    "            cv_scores = cross_val_score(model, X_train_selected, y_train, cv=cv, scoring='f1')\n",
    "            cv_mean = cv_scores.mean()\n",
    "            cv_std = cv_scores.std()\n",
    "            \n",
    "            print(f\"    CV F1: {cv_mean:.6f} ¬± {cv_std:.6f}\")\n",
    "            \n",
    "            if cv_mean > best_score:\n",
    "                best_score = cv_mean\n",
    "                best_features = top_features\n",
    "                best_count = k\n",
    "                \n",
    "                # ÏµúÍ≥† ÏÑ±Îä• Î™®Îç∏Î°ú ÏòàÏ∏°\n",
    "                model.fit(X_train_selected, y_train)\n",
    "                best_predictions = model.predict(X_test_selected)\n",
    "        \n",
    "        print(f\"\\n‚úÖ ÏµúÍ≥† ÏÑ±Îä•: {best_count}Í∞ú ÌäπÏÑ± (CV F1: {best_score:.6f})\")\n",
    "        print(f\"   ÏÑ†ÌÉùÎêú ÌäπÏÑ±: {best_features}\")\n",
    "        \n",
    "        submission = pd.DataFrame({'ID': test_ids, 'Cancer': best_predictions})\n",
    "        self.submissions['feature_selected'] = submission\n",
    "        self.selected_features['best'] = best_features\n",
    "        \n",
    "        return submission, best_features\n",
    "    \n",
    "    def ensemble_with_selected_features(self, X_train, y_train, X_test, test_ids, selected_features):\n",
    "        \"\"\"ÏÑ†ÌÉùÎêú ÌäπÏÑ±ÏúºÎ°ú ÏïôÏÉÅÎ∏î\"\"\"\n",
    "        print(f\"\\nü§ñ ÏÑ†ÌÉùÎêú {len(selected_features)}Í∞ú ÌäπÏÑ±ÏúºÎ°ú ÏïôÏÉÅÎ∏î...\")\n",
    "        \n",
    "        X_train_selected = X_train[selected_features]\n",
    "        X_test_selected = X_test[selected_features]\n",
    "        \n",
    "        pos_count = (y_train == 1).sum()\n",
    "        neg_count = (y_train == 0).sum()\n",
    "        scale_pos_weight = neg_count / pos_count\n",
    "        \n",
    "        # Îã§ÏñëÌïú Î™®Îç∏Î°ú ÏïôÏÉÅÎ∏î\n",
    "        models = {\n",
    "            'xgb_conservative': xgb.XGBClassifier(n_estimators=180, max_depth=5, learning_rate=0.07, random_state=42, scale_pos_weight=scale_pos_weight),\n",
    "            'xgb_balanced': xgb.XGBClassifier(n_estimators=160, max_depth=6, learning_rate=0.08, random_state=123, scale_pos_weight=scale_pos_weight),\n",
    "            'lgb': lgb.LGBMClassifier(n_estimators=160, max_depth=6, learning_rate=0.08, random_state=42, class_weight='balanced', verbose=-1),\n",
    "            'rf': RandomForestClassifier(n_estimators=160, max_depth=8, random_state=42, class_weight='balanced')\n",
    "        }\n",
    "        \n",
    "        # Cross-validationÏúºÎ°ú Í∞Å Î™®Îç∏ ÏÑ±Îä• ÌôïÏù∏\n",
    "        cv = StratifiedKFold(n_splits=5, shuffle=True, random_state=42)\n",
    "        model_scores = {}\n",
    "        model_predictions = {}\n",
    "        \n",
    "        for name, model in models.items():\n",
    "            cv_scores = cross_val_score(model, X_train_selected, y_train, cv=cv, scoring='f1')\n",
    "            model_scores[name] = cv_scores.mean()\n",
    "            print(f\"  {name}: CV F1 = {cv_scores.mean():.6f}\")\n",
    "            \n",
    "            # Ï†ÑÏ≤¥ Îç∞Ïù¥ÌÑ∞Î°ú ÌïôÏäµ\n",
    "            model.fit(X_train_selected, y_train)\n",
    "            model_predictions[name] = model.predict_proba(X_test_selected)[:, 1]\n",
    "        \n",
    "        # ÏÑ±Îä• Í∏∞Î∞ò Í∞ÄÏ§ë ÏïôÏÉÅÎ≥Ñ\n",
    "        total_score = sum(model_scores.values())\n",
    "        weights = [score/total_score for score in model_scores.values()]\n",
    "        \n",
    "        print(f\"  Í∞ÄÏ§ëÏπò: {dict(zip(model_scores.keys(), weights))}\")\n",
    "        \n",
    "        # Í∞ÄÏ§ë ÌèâÍ∑†\n",
    "        ensemble_proba = np.average(list(model_predictions.values()), axis=0, weights=weights)\n",
    "        ensemble_predictions = (ensemble_proba > 0.5).astype(int)\n",
    "        \n",
    "        submission = pd.DataFrame({'ID': test_ids, 'Cancer': ensemble_predictions})\n",
    "        self.submissions['feature_ensemble'] = submission\n",
    "        \n",
    "        return submission\n",
    "    \n",
    "    def ultra_simple_model(self, X_train, y_train, X_test, test_ids, selected_features):\n",
    "        \"\"\"Í∑πÎã®Ï†ÅÏúºÎ°ú Îã®ÏàúÌïú Î™®Îç∏\"\"\"\n",
    "        print(f\"\\nüéØ Í∑πÎã®Ï†Å Îã®ÏàúÌôî: ÏÉÅÏúÑ 5Í∞ú ÌäπÏÑ±Îßå ÏÇ¨Ïö©\")\n",
    "        \n",
    "        # ÏÉÅÏúÑ 5Í∞úÎßå ÏÑ†ÌÉù\n",
    "        top5_features = selected_features[:5]\n",
    "        print(f\"   ÏÇ¨Ïö© ÌäπÏÑ±: {top5_features}\")\n",
    "        \n",
    "        X_train_simple = X_train[top5_features]\n",
    "        X_test_simple = X_test[top5_features]\n",
    "        \n",
    "        pos_count = (y_train == 1).sum()\n",
    "        neg_count = (y_train == 0).sum()\n",
    "        scale_pos_weight = neg_count / pos_count\n",
    "        \n",
    "        # Îß§Ïö∞ Îã®ÏàúÌïú XGBoost\n",
    "        simple_model = xgb.XGBClassifier(\n",
    "            n_estimators=100,  # Ï†ÅÏùÄ Ìä∏Î¶¨\n",
    "            max_depth=4,       # ÏñïÏùÄ ÍπäÏù¥\n",
    "            learning_rate=0.1, \n",
    "            random_state=42,\n",
    "            scale_pos_weight=scale_pos_weight\n",
    "        )\n",
    "        \n",
    "        # CV ÌèâÍ∞Ä\n",
    "        cv = StratifiedKFold(n_splits=5, shuffle=True, random_state=42)\n",
    "        cv_scores = cross_val_score(simple_model, X_train_simple, y_train, cv=cv, scoring='f1')\n",
    "        \n",
    "        print(f\"   CV F1: {cv_scores.mean():.6f} ¬± {cv_scores.std():.6f}\")\n",
    "        \n",
    "        # ÌïôÏäµ Î∞è ÏòàÏ∏°\n",
    "        simple_model.fit(X_train_simple, y_train)\n",
    "        simple_predictions = simple_model.predict(X_test_simple)\n",
    "        \n",
    "        submission = pd.DataFrame({'ID': test_ids, 'Cancer': simple_predictions})\n",
    "        self.submissions['ultra_simple'] = submission\n",
    "        \n",
    "        return submission\n",
    "\n",
    "def run_feature_selection_optimization():\n",
    "    \"\"\"ÌäπÏÑ± ÏÑ†ÌÉù Í∏∞Î∞ò ÏµúÏ†ÅÌôî Ïã§Ìñâ\"\"\"\n",
    "    print(\"üéØ ÌäπÏÑ± Ï§ëÏöîÎèÑ Í∏∞Î∞ò Îã®ÏàúÌôî Ï†ÑÎûµ!\")\n",
    "    print(\"Î≥µÏû°Ìïú Í≤ÉÎ≥¥Îã§ Îã®ÏàúÌïú Í≤ÉÏù¥ ÎïåÎ°úÎäî Îçî Ï¢ãÏäµÎãàÎã§!\")\n",
    "    print(\"=\" * 60)\n",
    "    \n",
    "    analyzer = FeatureImportanceAnalyzer()\n",
    "    \n",
    "    # 1. Îç∞Ïù¥ÌÑ∞ Î°úÎî© Î∞è Ï†ÑÏ≤òÎ¶¨\n",
    "    X_train, y_train, X_test, test_ids, feature_cols = analyzer.load_and_preprocess()\n",
    "    \n",
    "    # 2. ÌäπÏÑ± Ï§ëÏöîÎèÑ Î∂ÑÏÑù\n",
    "    importance_df = analyzer.analyze_feature_importance(X_train, y_train, feature_cols)\n",
    "    \n",
    "    # 3. Îã§ÏñëÌïú ÌäπÏÑ± Ï°∞Ìï© ÌÖåÏä§Ìä∏\n",
    "    best_submission, best_features = analyzer.test_feature_combinations(\n",
    "        X_train, y_train, X_test, test_ids, importance_df\n",
    "    )\n",
    "    \n",
    "    # 4. ÏÑ†ÌÉùÎêú ÌäπÏÑ±ÏúºÎ°ú ÏïôÏÉÅÎ∏î\n",
    "    ensemble_submission = analyzer.ensemble_with_selected_features(\n",
    "        X_train, y_train, X_test, test_ids, best_features\n",
    "    )\n",
    "    \n",
    "    # 5. Í∑πÎã®Ï†Å Îã®ÏàúÌôî\n",
    "    simple_submission = analyzer.ultra_simple_model(\n",
    "        X_train, y_train, X_test, test_ids, best_features\n",
    "    )\n",
    "    \n",
    "    # 6. ÌååÏùº Ï†ÄÏû•\n",
    "    submissions_to_save = [\n",
    "        ('feature_selected_best.csv', best_submission, \"ÏµúÏ†Å ÌäπÏÑ± Ï°∞Ìï©\"),\n",
    "        ('feature_ensemble.csv', ensemble_submission, \"ÏÑ†ÌÉùÎêú ÌäπÏÑ± ÏïôÏÉÅÎ∏î\"),\n",
    "        ('ultra_simple.csv', simple_submission, \"Í∑πÎã®Ï†Å Îã®ÏàúÌôî\")\n",
    "    ]\n",
    "    \n",
    "    print(f\"\\nüíæ Ï†úÏ∂ú ÌååÏùº Ï†ÄÏû•...\")\n",
    "    for filename, submission, description in submissions_to_save:\n",
    "        submission.to_csv(filename, index=False)\n",
    "        \n",
    "        # ÏòàÏ∏° Î∂ÑÌè¨ ÌôïÏù∏\n",
    "        pred_dist = submission['Cancer'].value_counts()\n",
    "        print(f\"  {filename}: {description}\")\n",
    "        print(f\"    ÏòàÏ∏° Î∂ÑÌè¨ - 0: {pred_dist.get(0, 0)}, 1: {pred_dist.get(1, 0)}\")\n",
    "    \n",
    "    print(f\"\\nüéØ Ï†úÏ∂ú Ïö∞ÏÑ†ÏàúÏúÑ:\")\n",
    "    print(f\"1. feature_ensemble.csv ‚≠ê (ÏÑ†ÌÉùÎêú ÌäπÏÑ± ÏïôÏÉÅÎ∏î)\")\n",
    "    print(f\"2. feature_selected_best.csv (ÏµúÏ†Å ÌäπÏÑ± Ï°∞Ìï©)\")\n",
    "    print(f\"3. ultra_simple.csv (Í∑πÎã®Ï†Å Îã®ÏàúÌôî)\")\n",
    "    \n",
    "    print(f\"\\nüí° ÌïµÏã¨ ÏïÑÏù¥ÎîîÏñ¥:\")\n",
    "    print(f\"- Ï§ëÏöîÌïòÏßÄ ÏïäÏùÄ ÌäπÏÑ±Îì§Ïù¥ ÎÖ∏Ïù¥Ï¶àÎ•º ÎßåÎì§ Ïàò ÏûàÏùå\")\n",
    "    print(f\"- Îã®ÏàúÌïú Î™®Îç∏Ïù¥ ÏùºÎ∞òÌôî ÏÑ±Îä•Ïù¥ Îçî Ï¢ãÏùÑ Ïàò ÏûàÏùå\")\n",
    "    print(f\"- Í≥ºÏ†ÅÌï©ÏùÑ Ï§ÑÏó¨ÏÑú Ïã§Ï†ú ÏÑ±Îä• Ìñ•ÏÉÅ Í∞ÄÎä•\")\n",
    "    \n",
    "    # ÌäπÏÑ± Ï§ëÏöîÎèÑ ÏãúÍ∞ÅÌôî (ÏÑ†ÌÉùÏÇ¨Ìï≠)\n",
    "    print(f\"\\nüìä ÌäπÏÑ± Ï§ëÏöîÎèÑ Î∂ÑÏÑù ÏôÑÎ£å!\")\n",
    "    print(f\"ÏÉÅÏúÑ ÌäπÏÑ±Îì§: {best_features}\")\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    run_feature_selection_optimization()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
